{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f11644",
   "metadata": {},
   "source": [
    "\n",
    "# üìò Career Assistant ‚Äì ChatGPT-Powered (Gradio UI + Local CV & Background Files)\n",
    "\n",
    "This notebook loads:\n",
    "\n",
    "- **CV** ‚Üí from a local `cv.pdf`\n",
    "- **Background Information** ‚Üí from a local `background.txt`\n",
    "\n",
    "Then it automatically builds a **structured career profile** using ChatGPT.\n",
    "\n",
    "The Gradio UI only handles:\n",
    "- Recruiter's question ‚Üí Assistant answers as the candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1294d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install --quiet openai gradio pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033d9995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PROJECTS\\career assistant\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgr\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent, Runner, trace\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Initialize OpenAI client\u001b[39;00m\n\u001b[32m     10\u001b[39m client = OpenAI(api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'agents'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde80650",
   "metadata": {},
   "source": [
    "## üìÑ Load CV (PDF) and Background Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_pdf_text(pdf_path: str) -> str:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        txt = page.extract_text()\n",
    "        if txt:\n",
    "            text += txt + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "# Load files\n",
    "CV_PATH = \"cv.pdf\"\n",
    "BACKGROUND_PATH = \"background.txt\"\n",
    "\n",
    "cv_text = extract_pdf_text(CV_PATH)\n",
    "\n",
    "with open(BACKGROUND_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    background_text = f.read().strip()\n",
    "\n",
    "cv_text[:500], background_text[:300]  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04488b4d",
   "metadata": {},
   "source": [
    "## üß† Build Structured Career Profile Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ad79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_career_profile(cv_text, background):\n",
    "    prompt = f\"\"\"\n",
    "Extract a structured career profile based strictly on the information provided.\n",
    "\n",
    "CV CONTENT:\n",
    "{cv_text}\n",
    "\n",
    "BACKGROUND INFORMATION:\n",
    "{background}\n",
    "\n",
    "Return a structured professional profile containing:\n",
    "- Key skills\n",
    "- Technical tools\n",
    "- Work experience highlights\n",
    "- Academic strengths\n",
    "- Certifications (if any)\n",
    "- Major projects & impact\n",
    "- Soft skills\n",
    "- Career preferences\n",
    "- Strengths relevant to recruiters\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You extract structured candidate profiles.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "career_profile = build_career_profile(cv_text, background_text)\n",
    "career_profile[:800]  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca9db8",
   "metadata": {},
   "source": [
    "## üéôÔ∏è Recruiter Question ‚Üí Candidate Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_question(profile, question):\n",
    "    prompt = f\"\"\"\n",
    "You are acting as the candidate described below.\n",
    "Use only the information in the profile.\n",
    "If unsure, give a safe, reasonable answer.\n",
    "\n",
    "PROFILE:\n",
    "{profile}\n",
    "\n",
    "RECRUITER QUESTION:\n",
    "{question}\n",
    "\n",
    "Answer in first person (\"I\") and professionally.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You answer interview questions as the candidate.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3b3ae",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Gradio UI ‚Äì Recruiter Q&A Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ü§ñ Career Assistant ‚Äì ChatGPT (CV & Background Loaded From Code)\")\n",
    "    gr.Markdown(\"Ask any recruiter question. The assistant will answer as the candidate.\")\n",
    "    \n",
    "    question = gr.Textbox(label=\"Recruiter's Question\", lines=2)\n",
    "    answer = gr.Textbox(label=\"Candidate's Response\", lines=8)\n",
    "    \n",
    "    ask_btn = gr.Button(\"Ask\")\n",
    "    \n",
    "    ask_btn.click(\n",
    "        fn=answer_question,\n",
    "        inputs=[gr.State(career_profile), question],\n",
    "        outputs=answer\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f10e7",
   "metadata": {},
   "source": [
    "### With Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üîí Demonstrating OpenAI‚Äôs Built-In Guardrails (Natural Language Mode)\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def guarded_interview_response(question):\n",
    "    \"\"\"\n",
    "    Demonstrates OpenAI‚Äôs built-in guardrails:\n",
    "    - Detects inappropriate / discriminatory interview questions\n",
    "    - Automatically refuses unsafe content\n",
    "    - Keeps responses professional and safe\n",
    "    - Uses OpenAI's native safety system (not manual rules)\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a job interview candidate with OpenAI safety guardrails enabled.\\n\"\n",
    "                    \"Follow these rules strictly:\\n\"\n",
    "                    \"1. Reject inappropriate, discriminatory, or illegal interview questions.\\n\"\n",
    "                    \"2. If a question violates employment law or privacy norms, politely decline.\\n\"\n",
    "                    \"3. If the question is allowed, answer normally and professionally.\\n\"\n",
    "                    \"4. NEVER reveal or fabricate sensitive attributes (age, race, religion, politics, etc.).\\n\"\n",
    "                    \"5. Keep responses natural and conversational ‚Äî do NOT use JSON or structured formats.\\n\"\n",
    "                    \"6. Use refusal guidelines when necessary:\\n\"\n",
    "                    \"   - ‚ÄúI'm not able to answer that question.‚Äù\\n\"\n",
    "                    \"   - ‚ÄúThat‚Äôs not appropriate for a job interview.‚Äù\\n\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        # built-in guardrails feature (OpenAI SDK, 2024+)\n",
    "        response_format={\"type\": \"guardrails\"}  \n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# üîç Try guardrails demo\n",
    "test_questions = [\n",
    "    \"Do you plan on having children soon?\",\n",
    "    \"What's your religion?\",\n",
    "    \"What is your greatest strength?\",\n",
    "    \"Tell me about your experience working with Python.\",\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"Q: {q}\")\n",
    "    print(\"A:\", guarded_interview_response(q))\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
